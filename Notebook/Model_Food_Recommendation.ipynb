{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf1a36-79d0-4b5f-8283-7c47fcaa97df",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4d87e-0f4d-4c3f-84df-6a45be21513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4e5cf-9d86-44d0-a9a3-fa2b50aa8c6d",
   "metadata": {},
   "source": [
    "Read csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89faa423-2168-4b51-8b9b-0e7e40c8b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/Capstone-Project-CH-PS426/Machine-Learning/main/Dataset/content_food.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "df = df[['name', 'nutrition', 'skintype', 'benefit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3c227-1c41-417e-9f07-1b8f664521f3",
   "metadata": {},
   "source": [
    "Convert 'skintype' column to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905a5e4-dee9-47e0-86a8-004846d2fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['skintype'] = df['skintype'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef624c9-692e-4590-b236-4c210b6516cd",
   "metadata": {},
   "source": [
    "Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016cf62-c575-41f2-b037-f5b9d38794f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['skintype_encoded'] = label_encoder.fit_transform(df['skintype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1983dfa4-fbcb-4eb9-835e-0eb733a79cd6",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111695a-c279-4d89-9baa-ce82ae8d0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f88ee-95a5-43c2-9a70-c44db3482b61",
   "metadata": {},
   "source": [
    "Build a simple neural network model to learn embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d4b3b-45a7-4a71-b789-a5a046c9d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=50, input_length=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99422ed1-1738-447b-8a48-bf8e76146d57",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d6a1b-6fca-4d56-a242-772822fead2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_df['skintype_encoded'], train_df['skintype_encoded'], epochs=80, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356406e-2527-43fd-84b2-581cf14933df",
   "metadata": {},
   "source": [
    "Extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30a6df-0af0-4e19-9e2e-a90c5fe95ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Sequential(model.layers[:-1])  # Remove the output layer\n",
    "embeddings = embedding_model.predict(np.arange(len(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bce0ab-4df9-4c97-b361-95452d052efa",
   "metadata": {},
   "source": [
    "Calculate Similarity using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7924e8-b6b9-4b71-9972-aa18978f65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48187bf4-b542-4c27-b508-bc77d69d0adb",
   "metadata": {},
   "source": [
    "Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de5a51-6f0c-42f4-be6f-cf38513b54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_skin_type, similarity_matrix, top=10):\n",
    "    try:\n",
    "        # Convert user input to lowercase for case-insensitive comparison\n",
    "        user_skin_type = user_skin_type.lower()\n",
    "\n",
    "        # Find the index of the product with the specified skin type\n",
    "        index = df[df['skintype'] == user_skin_type].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"No data available for the specified skin type: {user_skin_type}\")\n",
    "        return\n",
    "\n",
    "    distances = sorted(enumerate(similarity_matrix[index]), reverse=True, key=lambda x: x[1])\n",
    "\n",
    "    # Print Recommendation for user skin type\n",
    "    print(f\"Top {top} Recommendations for {user_skin_type} skin type:\")\n",
    "    for i in distances[1:top+1]:\n",
    "        print(f\"{df.iloc[i[0]]['name']} ({df.iloc[i[0]]['benefit']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e6028-7bad-4fa2-87d8-d587907c2c2b",
   "metadata": {},
   "source": [
    "Save model list products (all products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa93540-b9ae-4752-bfd9-c1bcc8410738",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list_foods.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "# Save model similarity results\n",
    "with open('similarity_foods.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c4912-83a5-4d0b-a66b-fc26670fb573",
   "metadata": {},
   "source": [
    "FULL CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c804bf0-4058-4a6d-b21e-4f818eb249c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 1s 10ms/step - loss: 2.8370 - accuracy: 0.0000e+00\n",
      "Epoch 2/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8243 - accuracy: 0.1290\n",
      "Epoch 3/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8168 - accuracy: 0.1290\n",
      "Epoch 4/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8091 - accuracy: 0.1290\n",
      "Epoch 5/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8013 - accuracy: 0.1290\n",
      "Epoch 6/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7926 - accuracy: 0.1290\n",
      "Epoch 7/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7836 - accuracy: 0.1290\n",
      "Epoch 8/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7713 - accuracy: 0.1290\n",
      "Epoch 9/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7596 - accuracy: 0.1290\n",
      "Epoch 10/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7443 - accuracy: 0.1290\n",
      "Epoch 11/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7320 - accuracy: 0.1290\n",
      "Epoch 12/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7138 - accuracy: 0.1290\n",
      "Epoch 13/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6937 - accuracy: 0.1290\n",
      "Epoch 14/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6686 - accuracy: 0.1290\n",
      "Epoch 15/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6417 - accuracy: 0.1290\n",
      "Epoch 16/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6103 - accuracy: 0.1290\n",
      "Epoch 17/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5753 - accuracy: 0.1290\n",
      "Epoch 18/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5359 - accuracy: 0.1290\n",
      "Epoch 19/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4908 - accuracy: 0.1290\n",
      "Epoch 20/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4423 - accuracy: 0.1290\n",
      "Epoch 21/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3943 - accuracy: 0.1290\n",
      "Epoch 22/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3322 - accuracy: 0.1613\n",
      "Epoch 23/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2736 - accuracy: 0.1935\n",
      "Epoch 24/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2042 - accuracy: 0.1935\n",
      "Epoch 25/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1340 - accuracy: 0.1935\n",
      "Epoch 26/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0757 - accuracy: 0.1935\n",
      "Epoch 27/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0068 - accuracy: 0.3548\n",
      "Epoch 28/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9480 - accuracy: 0.4516\n",
      "Epoch 29/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8875 - accuracy: 0.4516\n",
      "Epoch 30/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8242 - accuracy: 0.4516\n",
      "Epoch 31/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7631 - accuracy: 0.4516\n",
      "Epoch 32/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7088 - accuracy: 0.4516\n",
      "Epoch 33/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6517 - accuracy: 0.4839\n",
      "Epoch 34/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5920 - accuracy: 0.5161\n",
      "Epoch 35/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5353 - accuracy: 0.5161\n",
      "Epoch 36/80\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4863 - accuracy: 0.5161\n",
      "Epoch 37/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4356 - accuracy: 0.5161\n",
      "Epoch 38/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3902 - accuracy: 0.5161\n",
      "Epoch 39/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3448 - accuracy: 0.6452\n",
      "Epoch 40/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3014 - accuracy: 0.6452\n",
      "Epoch 41/80\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2628 - accuracy: 0.6452\n",
      "Epoch 42/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2234 - accuracy: 0.6452\n",
      "Epoch 43/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1808 - accuracy: 0.6452\n",
      "Epoch 44/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1407 - accuracy: 0.6452\n",
      "Epoch 45/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1025 - accuracy: 0.6452\n",
      "Epoch 46/80\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0637 - accuracy: 0.6774\n",
      "Epoch 47/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0227 - accuracy: 0.7097\n",
      "Epoch 48/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9804 - accuracy: 0.7097\n",
      "Epoch 49/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9376 - accuracy: 0.7742\n",
      "Epoch 50/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8997 - accuracy: 0.7742\n",
      "Epoch 51/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8563 - accuracy: 0.7742\n",
      "Epoch 52/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8188 - accuracy: 0.7742\n",
      "Epoch 53/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7825 - accuracy: 0.8065\n",
      "Epoch 54/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7443 - accuracy: 0.8387\n",
      "Epoch 55/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.8387\n",
      "Epoch 56/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.8387\n",
      "Epoch 57/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.8387\n",
      "Epoch 58/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6082 - accuracy: 0.8387\n",
      "Epoch 59/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.8387\n",
      "Epoch 60/80\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5436 - accuracy: 0.8387\n",
      "Epoch 61/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.8387\n",
      "Epoch 62/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.8387\n",
      "Epoch 63/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.9032\n",
      "Epoch 64/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.9032\n",
      "Epoch 65/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.9032\n",
      "Epoch 66/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.9032\n",
      "Epoch 67/80\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.9032\n",
      "Epoch 68/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.9032\n",
      "Epoch 69/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.9032\n",
      "Epoch 70/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8710\n",
      "Epoch 71/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8710\n",
      "Epoch 72/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8710\n",
      "Epoch 73/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2519 - accuracy: 0.9032\n",
      "Epoch 74/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9355\n",
      "Epoch 75/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9355\n",
      "Epoch 76/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2124 - accuracy: 0.9355\n",
      "Epoch 77/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2001 - accuracy: 0.9355\n",
      "Epoch 78/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9355\n",
      "Epoch 79/80\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9355\n",
      "Epoch 80/80\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1688 - accuracy: 0.9355\n",
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import pickle\n",
    "\n",
    "# Read csv\n",
    "data_url = 'https://raw.githubusercontent.com/Capstone-Project-CH-PS426/Machine-Learning/main/Dataset/content_food.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "df = df[['name', 'nutrition', 'skintype', 'benefit']]\n",
    "\n",
    "# Convert 'skintype' column to lowercase\n",
    "df['skintype'] = df['skintype'].str.lower()\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "df['skintype_encoded'] = label_encoder.fit_transform(df['skintype'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple neural network model to learn embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=50, input_length=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_df['skintype_encoded'], train_df['skintype_encoded'], epochs=80, batch_size=16)\n",
    "\n",
    "# Extract embeddings\n",
    "embedding_model = Sequential(model.layers[:-1])  # Remove the output layer\n",
    "embeddings = embedding_model.predict(np.arange(len(label_encoder.classes_)))\n",
    "\n",
    "# Calculate Similarity using embeddings\n",
    "similarity = cosine_similarity(embeddings)\n",
    "\n",
    "# Recommendation Function\n",
    "def recommend(user_skin_type, similarity_matrix, top=10):\n",
    "    try:\n",
    "        # Convert user input to lowercase for case-insensitive comparison\n",
    "        user_skin_type = user_skin_type.lower()\n",
    "\n",
    "        # Find the index of the product with the specified skin type\n",
    "        index = df[df['skintype'] == user_skin_type].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"No data available for the specified skin type: {user_skin_type}\")\n",
    "        return\n",
    "\n",
    "    distances = sorted(enumerate(similarity_matrix[index]), reverse=True, key=lambda x: x[1])\n",
    "\n",
    "    # Print Recommendation for user skin type\n",
    "    print(f\"Top {top} Recommendations for {user_skin_type} skin type:\")\n",
    "    for i in distances[1:top+1]:\n",
    "        print(f\"{df.iloc[i[0]]['name']} ({df.iloc[i[0]]['benefit']})\")\n",
    "\n",
    "# Save model list products (all products)\n",
    "with open('list_foods.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "# Save model similarity results\n",
    "with open('similarity_foods.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1b817f-fc7e-40ab-a8ac-60323f14f305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your skin type (e.g., Normal, Dry, Oily, Combination, Sensitive):  dry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for dry skin type:\n",
      "Pomegranate (Hydrating, Antioxidant)\n",
      "Guava (Brightening)\n",
      "Sweet Potato (Anti-aging, Skin-renewal)\n",
      "Lemon (Brightening)\n",
      "Coffee (Anti-inflammatory, Antibacterial, Oil-control)\n",
      "Salmon (Moisturizing, Anti-inflammatory, Skin-repair )\n",
      "Almonds (Hydrating, Anti-inflammatory, Skin-renewal)\n",
      "Nuts (Hydrating, Antioxidants, Moisturizing)\n",
      "Orange (Hydrating, Anti-inflammatory, Antibacterial, Oil-control, Skin-lightening)\n",
      "Avocado (Hydrating, Antioxidants, Moisturizing)\n"
     ]
    }
   ],
   "source": [
    "user_input_skin_type = input(\"Enter your skin type (e.g., Normal, Dry, Oily, Combination, Sensitive): \")\n",
    "recommend(user_input_skin_type, similarity, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9d685-2b8b-4002-809f-8b70dae7d9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
