{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69df7bf7-b18a-4de8-9190-21c0302f6582",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9087c60-daf1-4eeb-bc9d-d60a0c66ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca3ed8-baed-4f9f-9126-b06ce4a26132",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d5eca-36ec-471e-9afe-69bf85966776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/Capstone-Project-CH-PS426/Machine-Learning/main/Dataset/content_product.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "df = df[['name', 'brand', 'type', 'composition', 'skintype']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31857087-6718-49b5-9240-9cf0551314eb",
   "metadata": {},
   "source": [
    "Convert 'skintype' column to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd83a7-6df4-48a8-a66f-133d09da2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['skintype'] = df['skintype'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d529830-5269-46c9-919b-704d45a87647",
   "metadata": {},
   "source": [
    "Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c15c9-d2e9-477a-b96c-bd5f336dbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['skintype_encoded'] = label_encoder.fit_transform(df['skintype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac1756-f886-480c-9b00-5c85cc624ca5",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd1f71-051d-48ac-878b-6ddea828f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2933eb-943f-4ab8-936b-cb2fc85f8bf1",
   "metadata": {},
   "source": [
    "Build a simple neural network model to learn embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dca334-aa26-46aa-bad0-11665ed1ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=50, input_length=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ae67c-af75-4b6b-b6e4-17cc8ef3ed24",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07491e4b-da7c-4fca-95ec-862b59ab74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_df['skintype_encoded'], train_df['skintype_encoded'], epochs=70, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce22abf-7c8a-42c1-9ccb-981354b5f9fe",
   "metadata": {},
   "source": [
    "Extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30000b03-b274-40d4-8654-cec0b6b1a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Sequential(model.layers[:-1])  # Remove the output layer\n",
    "embeddings = embedding_model.predict(np.arange(len(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c3a467-1be7-4c84-aa6a-5edee6ef64a2",
   "metadata": {},
   "source": [
    "Calculate Similarity using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de78289-93f1-4f93-af5c-5a0ef4079a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3468dc-b3a8-48e9-8bde-773942c14ee1",
   "metadata": {},
   "source": [
    "Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b7990-4246-4d43-9c03-17e5ee1141d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_skin_type, similarity_matrix, top=10):\n",
    "    try:\n",
    "        # Convert user input to lowercase for case-insensitive comparison\n",
    "        user_skin_type = user_skin_type.lower()\n",
    "\n",
    "        # Find the index of the product with the specified skin type\n",
    "        index = df[df['skintype'] == user_skin_type].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"No data available for the specified skin type: {user_skin_type}\")\n",
    "        return\n",
    "\n",
    "    distances = sorted(enumerate(similarity_matrix[index]), reverse=True, key=lambda x: x[1])\n",
    "\n",
    "# Print Recommendation for user skin type\n",
    "    print(f\"Top {top} Recommendations for {user_skin_type} skin type:\")\n",
    "    for i in distances[1:top+1]:\n",
    "        print(f\"{df.iloc[i[0]]['name']} ({df.iloc[i[0]]['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b968b-f700-42d5-b762-d1622c2d9288",
   "metadata": {},
   "source": [
    "Save model list products (all products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9da217-8e92-4261-b89a-9e1ae596410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list_products.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "# Save model similarity results\n",
    "with open('similarity_products.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d21c27-1830-4fc7-add1-02db37261e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 2.9928 - accuracy: 0.1944\n",
      "Epoch 2/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9794 - accuracy: 0.2778\n",
      "Epoch 3/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9674 - accuracy: 0.3611\n",
      "Epoch 4/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9544 - accuracy: 0.3056\n",
      "Epoch 5/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9409 - accuracy: 0.3056\n",
      "Epoch 6/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9252 - accuracy: 0.3056\n",
      "Epoch 7/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9075 - accuracy: 0.3056\n",
      "Epoch 8/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8870 - accuracy: 0.3056\n",
      "Epoch 9/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8620 - accuracy: 0.3056\n",
      "Epoch 10/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8345 - accuracy: 0.3056\n",
      "Epoch 11/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8030 - accuracy: 0.3056\n",
      "Epoch 12/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.7650 - accuracy: 0.3056\n",
      "Epoch 13/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.7213 - accuracy: 0.3056\n",
      "Epoch 14/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6705 - accuracy: 0.3056\n",
      "Epoch 15/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6137 - accuracy: 0.3056\n",
      "Epoch 16/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.5488 - accuracy: 0.3056\n",
      "Epoch 17/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.4744 - accuracy: 0.3056\n",
      "Epoch 18/75\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.4011 - accuracy: 0.3056\n",
      "Epoch 19/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.3199 - accuracy: 0.3056\n",
      "Epoch 20/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.2343 - accuracy: 0.3056\n",
      "Epoch 21/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1451 - accuracy: 0.3056\n",
      "Epoch 22/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.0600 - accuracy: 0.3056\n",
      "Epoch 23/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9705 - accuracy: 0.3056\n",
      "Epoch 24/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.8839 - accuracy: 0.3056\n",
      "Epoch 25/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.8000 - accuracy: 0.3056\n",
      "Epoch 26/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7176 - accuracy: 0.3056\n",
      "Epoch 27/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.6281 - accuracy: 0.3056\n",
      "Epoch 28/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5511 - accuracy: 0.3056\n",
      "Epoch 29/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4766 - accuracy: 0.3333\n",
      "Epoch 30/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4002 - accuracy: 0.5833\n",
      "Epoch 31/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3320 - accuracy: 0.6389\n",
      "Epoch 32/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2635 - accuracy: 0.6389\n",
      "Epoch 33/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1922 - accuracy: 0.6389\n",
      "Epoch 34/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1268 - accuracy: 0.6389\n",
      "Epoch 35/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.6389\n",
      "Epoch 36/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.6389\n",
      "Epoch 37/75\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9733 - accuracy: 0.6389\n",
      "Epoch 38/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9355 - accuracy: 0.6389\n",
      "Epoch 39/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9051 - accuracy: 0.6389\n",
      "Epoch 40/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8792 - accuracy: 0.6667\n",
      "Epoch 41/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8537 - accuracy: 0.6667\n",
      "Epoch 42/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8321 - accuracy: 0.6944\n",
      "Epoch 43/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8118 - accuracy: 0.7222\n",
      "Epoch 44/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7904 - accuracy: 0.7500\n",
      "Epoch 45/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.8056\n",
      "Epoch 46/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7471 - accuracy: 0.8056\n",
      "Epoch 47/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.8333\n",
      "Epoch 48/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.8333\n",
      "Epoch 49/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.8333\n",
      "Epoch 50/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.8333\n",
      "Epoch 51/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.8333\n",
      "Epoch 52/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.8333\n",
      "Epoch 53/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.8333\n",
      "Epoch 54/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.8333\n",
      "Epoch 55/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.8611\n",
      "Epoch 56/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.8611\n",
      "Epoch 57/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.8611\n",
      "Epoch 58/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.8611\n",
      "Epoch 59/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8611\n",
      "Epoch 60/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.8611\n",
      "Epoch 61/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8611\n",
      "Epoch 62/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8611\n",
      "Epoch 63/75\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8611\n",
      "Epoch 64/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8611\n",
      "Epoch 65/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8611\n",
      "Epoch 66/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8611\n",
      "Epoch 67/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8611\n",
      "Epoch 68/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8889\n",
      "Epoch 69/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8889\n",
      "Epoch 70/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8889\n",
      "Epoch 71/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.9444\n",
      "Epoch 72/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.9444\n",
      "Epoch 73/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.9444\n",
      "Epoch 74/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.9722\n",
      "Epoch 75/75\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.9722\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021F1D5CE3E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "import pickle\n",
    "\n",
    "# Read csv\n",
    "data_url = 'https://raw.githubusercontent.com/Capstone-Project-CH-PS426/Machine-Learning/main/Dataset/content_product.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "df = df[['name', 'brand', 'type', 'composition', 'skintype']]\n",
    "\n",
    "# Convert 'skintype' column to lowercase\n",
    "df['skintype'] = df['skintype'].str.lower()\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "df['skintype_encoded'] = label_encoder.fit_transform(df['skintype'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple neural network model to learn embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=50, input_length=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_df['skintype_encoded'], train_df['skintype_encoded'], epochs=75, batch_size=16)\n",
    "\n",
    "# Extract embeddings\n",
    "embedding_model = Sequential(model.layers[:-1])  # Remove the output layer\n",
    "embeddings = embedding_model.predict(np.arange(len(label_encoder.classes_)))\n",
    "\n",
    "# Calculate Similarity using embeddings\n",
    "similarity = cosine_similarity(embeddings)\n",
    "\n",
    "# Recommendation Function\n",
    "def recommend(user_skin_type, similarity_matrix, top=10):\n",
    "    try:\n",
    "        # Convert user input to lowercase for case-insensitive comparison\n",
    "        user_skin_type = user_skin_type.lower()\n",
    "\n",
    "        # Find the index of the product with the specified skin type\n",
    "        index = df[df['skintype'] == user_skin_type].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"No data available for the specified skin type: {user_skin_type}\")\n",
    "        return\n",
    "\n",
    "    distances = sorted(enumerate(similarity_matrix[index]), reverse=True, key=lambda x: x[1])\n",
    "\n",
    "    # Print Recommendation for user skin type\n",
    "    print(f\"Top {top} Recommendations for {user_skin_type} skin type:\")\n",
    "    for i in distances[1:top+1]:\n",
    "        print(f\"{df.iloc[i[0]]['name']} ({df.iloc[i[0]]['type']})\")\n",
    "\n",
    "# Save model list products (all products)\n",
    "with open('list_products.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "# Save model similarity results\n",
    "with open('similarity_products.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792e64b-012c-44e9-81dc-f1037a9cb4ee",
   "metadata": {},
   "source": [
    "User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e3026f-7004-40df-969e-d8019aacaf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your skin type (e.g., Normal, Dry, Oily, Combination, Sensitive):  oily\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for oily skin type:\n",
      "Cetaphil Gentle Cleanser (Facewash)\n",
      "Dear Klairs Supple Preparation Unscented Toner (Toner)\n",
      "Safi White Expert Oil Control & Anti Acne Facial Cleanser (Facewash)\n",
      "Cerave Foaming Facial Cleanser (Facewash)\n",
      "SKINTIFIC Ultra Light Serum Sunscreen (Sunscreen)\n",
      "Iâ€™m from Rice Toner (Toner)\n",
      "Emina Bright Stuff Face Wash (Facewash)\n",
      "5X Ceramide Soothing Toner Skintific (Toner)\n",
      "Senka Perfect Whip Acne Care (Facewash)\n",
      "Emina Face Wash Ms Pimple Acne Solution (Facewash)\n"
     ]
    }
   ],
   "source": [
    "user_input_skin_type = input(\"Enter your skin type (e.g., Normal, Dry, Oily, Combination, Sensitive): \")\n",
    "recommend(user_input_skin_type, similarity, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0755f-7de6-4ef8-a7e2-237af3ca8593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
